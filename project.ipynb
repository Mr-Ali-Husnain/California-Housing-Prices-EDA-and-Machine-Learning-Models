{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df8fab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# OOP Based EDA & ML Pipeline for Housing Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# ======================== #\n",
    "# 1️ Data Loading & Overview\n",
    "# ======================== #\n",
    "class DataLoader:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.df = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "        print(\"Data Loaded Successfully!\\n\")\n",
    "        return self.df\n",
    "\n",
    "    def show_info(self):\n",
    "        print(\"\\nDataset Info:\")\n",
    "        return self.df.info()\n",
    "\n",
    "    def show_head(self, n=5):\n",
    "        print(f\"\\nFirst {n} Rows:\")\n",
    "        return self.df.head(n)\n",
    "\n",
    "    def show_tail(self, n=5):\n",
    "        print(f\"\\nLast {n} Rows:\")\n",
    "        return self.df.tail(n)\n",
    "\n",
    "    def describe_data(self):\n",
    "        print(\"\\nStatistical Summary:\")\n",
    "        return self.df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea1900",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# 2️ Generalized Data Cleaner\n",
    "# ======================== #\n",
    "\n",
    "class DataCleaner:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    # Check Missing Values\n",
    "    def check_missing(self):\n",
    "        print(\"\\nMissing Values in Each Column:\")\n",
    "        missing = self.df.isnull().sum()\n",
    "        print(missing[missing > 0] if missing.sum() > 0 else \"No missing values found.\")\n",
    "        return missing\n",
    "\n",
    "    # Fill Missing Values (auto handle both numeric + categorical)\n",
    "    def fill_missing(self):\n",
    "        print(\"\\nHandling missing values automatically...\")\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].isnull().sum() > 0:\n",
    "                if pd.api.types.is_numeric_dtype(self.df[col]):\n",
    "                    self.df[col].fillna(self.df[col].median(), inplace=True)\n",
    "                    print(f\"   • '{col}' → filled with median ({self.df[col].median():.2f})\")\n",
    "                else:\n",
    "                    self.df[col].fillna(self.df[col].mode()[0], inplace=True)\n",
    "                    print(f\"   • '{col}' → filled with mode ('{self.df[col].mode()[0]}')\")\n",
    "\n",
    "        print(\"All missing values handled successfully.\")\n",
    "        return self.df\n",
    "\n",
    "    # Remove Duplicate Rows\n",
    "    def remove_duplicates(self):\n",
    "        before = len(self.df)\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "        after = len(self.df)\n",
    "        print(f\"\\nRemoved {before - after} duplicate rows.\")\n",
    "        return self.df\n",
    "\n",
    "    # Remove Outliers (IQR Method)\n",
    "    def remove_outliers(self):\n",
    "        print(\"\\nRemoving outliers using IQR method...\")\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            Q1 = self.df[col].quantile(0.25)\n",
    "            Q3 = self.df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "\n",
    "            before = len(self.df)\n",
    "            self.df = self.df[(self.df[col] >= lower) & (self.df[col] <= upper)]\n",
    "            after = len(self.df)\n",
    "            if before != after:\n",
    "                print(f\"   • '{col}' → Removed {before - after} outliers.\")\n",
    "\n",
    "        print(\"Outlier removal complete.\")\n",
    "        return self.df\n",
    "\n",
    "    # Smooth Noisy Data (Rolling Mean)\n",
    "    def smooth_noisy_data(self, window=3):\n",
    "        print(f\"\\nApplying rolling mean smoothing (window={window})...\")\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            self.df[col] = self.df[col].rolling(window=window, min_periods=1).mean()\n",
    "        print(\"Noise reduction applied successfully.\")\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565d84d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# 3️ Data Analysis\n",
    "# ======================== #\n",
    "class DataAnalyzer:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def correlation_matrix(self):\n",
    "        print(\"\\nCorrelation Matrix:\")\n",
    "        numeric_df = self.df.select_dtypes(include=[np.number])\n",
    "        corr = numeric_df.corr()\n",
    "        print(corr)\n",
    "        return corr\n",
    "\n",
    "    def highest_correlations(self, target, top_n=5):\n",
    "        numeric_df = self.df.select_dtypes(include=[np.number])\n",
    "        if target not in numeric_df.columns:\n",
    "            print(f\"'{target}' is not numeric! Convert or encode it before correlation.\")\n",
    "            return None\n",
    "\n",
    "        corr = numeric_df.corr()[target].abs().sort_values(ascending=False)\n",
    "        print(f\"\\nTop {top_n} correlated features with '{target}':\")\n",
    "        print(corr.head(top_n))\n",
    "        return corr.head(top_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73acf562",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# 4️ Data Visualization\n",
    "# ======================== #\n",
    "class DataVisualizer:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def plot_distributions(self):\n",
    "        self.df.hist(figsize=(12, 8), bins=20)\n",
    "        plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "    def correlation_heatmap(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(self.df.select_dtypes(include='number').corr(), annot=True, cmap=\"coolwarm\")\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        plt.show()\n",
    "\n",
    "    def ocean_proximity_count(self):\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.countplot(x='ocean_proximity', data=self.df)\n",
    "        plt.title(\"Ocean Proximity Count\")\n",
    "        plt.show()\n",
    "\n",
    "    def income_vs_value(self):\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.scatterplot(x='median_income', y='median_house_value', data=self.df, alpha=0.5)\n",
    "        plt.title(\"Income vs House Value\")\n",
    "        plt.xlabel(\"Median Income\")\n",
    "        plt.ylabel(\"Median House Value\")\n",
    "        plt.show()\n",
    "\n",
    "    def boxplot_features(self):\n",
    "        numeric_cols = self.df.select_dtypes(include='number').columns\n",
    "        plt.figure(figsize=(15,8))\n",
    "        self.df[numeric_cols].boxplot()\n",
    "        plt.title(\"Boxplot of Numeric Features (Outlier Detection)\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "    def geo_distribution(self):\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.scatterplot(x='longitude', y='latitude', hue='median_house_value', data=self.df, palette='coolwarm', alpha=0.6)\n",
    "        plt.title(\"Geographical Distribution of House Prices\")\n",
    "        plt.show()\n",
    "\n",
    "    def avg_price_per_ocean(self):\n",
    "        avg_prices = self.df.groupby('ocean_proximity')['median_house_value'].mean().sort_values()\n",
    "        plt.figure(figsize=(7,5))\n",
    "        sns.barplot(x=avg_prices.index, y=avg_prices.values, palette='viridis')\n",
    "        plt.title(\"Average House Value by Ocean Proximity\")\n",
    "        plt.xlabel(\"Ocean Proximity\")\n",
    "        plt.ylabel(\"Average House Value\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6013585",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# 5️ Data Preprocessing\n",
    "# ======================== #\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def encode_and_split(self, target):\n",
    "        print(\"\\nEncoding categorical features...\")\n",
    "        le = LabelEncoder()\n",
    "        self.df['ocean_proximity'] = le.fit_transform(self.df['ocean_proximity'])\n",
    "\n",
    "        X = self.df.drop(columns=[target])\n",
    "        y = self.df[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"Data split into train and test sets.\")\n",
    "        return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0b824",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# 6️ Model Selection\n",
    "# ======================== #\n",
    "class ModelSelector:\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def compare_models(self):\n",
    "        print(\"\\nComparing Models with LazyPredict...\")\n",
    "        reg = LazyRegressor(verbose=0, ignore_warnings=True)\n",
    "        models, predictions = reg.fit(self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        print(models)\n",
    "        return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c06ba2d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# 7️ Model Training\n",
    "# ======================== #\n",
    "class ModelTrainer:\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def train_best_model(self):\n",
    "        print(\"\\nTraining RandomForestRegressor as best model...\")\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        print(\"Model trained successfully.\")\n",
    "        return model, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2374f71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# 8️ Model Evaluation\n",
    "# ======================== #\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, y_test, y_pred):\n",
    "        self.y_test = y_test\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(\"\\nModel Performance:\")\n",
    "        print(f\"MAE: {mean_absolute_error(self.y_test, self.y_pred):.2f}\")\n",
    "        print(f\"MSE: {mean_squared_error(self.y_test, self.y_pred):.2f}\")\n",
    "        print(f\"R² Score: {r2_score(self.y_test, self.y_pred):.2f}\")\n",
    "\n",
    "    def plot_confusion_matrix(self):\n",
    "        y_true = np.round(self.y_test / 50000).astype(int)\n",
    "        y_pred = np.round(self.y_pred / 50000).astype(int)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=\"Blues\")\n",
    "        plt.title(\"Confusion Matrix (Binned Target)\")\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91048bec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "#  Execution Pipeline\n",
    "# ======================== #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"housing.csv\"   # <-- apna dataset ka path yahan daalein\n",
    "    target_col = \"median_house_value\"\n",
    "\n",
    "    # 1️ Data Loading\n",
    "    loader = DataLoader(file_path)\n",
    "    df = loader.load_data()\n",
    "    loader.show_info()\n",
    "    print(loader.show_head())\n",
    "\n",
    "    # 2️ Data Cleaning\n",
    "    cleaner = DataCleaner(df)\n",
    "    cleaner.check_missing()\n",
    "    df = cleaner.fill_missing()\n",
    "    df = cleaner.remove_duplicates()\n",
    "    df = cleaner.remove_outliers()\n",
    "    df = cleaner.smooth_noisy_data(window=3)\n",
    "\n",
    "    # 3️ Data Analysis\n",
    "    analyzer = DataAnalyzer(df)\n",
    "    analyzer.correlation_matrix()\n",
    "    analyzer.highest_correlations(target_col, top_n=5)\n",
    "\n",
    "    # 4️ Data Visualization\n",
    "    viz = DataVisualizer(df)\n",
    "    viz.plot_distributions()\n",
    "    viz.correlation_heatmap()\n",
    "    viz.ocean_proximity_count()\n",
    "    viz.income_vs_value()\n",
    "    viz.boxplot_features()\n",
    "    viz.geo_distribution()\n",
    "    viz.avg_price_per_ocean()\n",
    "\n",
    "    # 5️ Data Preprocessing\n",
    "    pre = DataPreprocessor(df)\n",
    "    X_train, X_test, y_train, y_test = pre.encode_and_split(target_col)\n",
    "\n",
    "    # 6️ Model Selection\n",
    "    selector = ModelSelector(X_train, X_test, y_train, y_test)\n",
    "    models = selector.compare_models()\n",
    "\n",
    "    # 7️ Model Training\n",
    "    trainer = ModelTrainer(X_train, X_test, y_train, y_test)\n",
    "    model, y_pred = trainer.train_best_model()\n",
    "\n",
    "    # 8️ Model Evaluation\n",
    "    evaluator = ModelEvaluator(y_test, y_pred)\n",
    "    evaluator.evaluate()\n",
    "    evaluator.plot_confusion_matrix()\n",
    "\n",
    "    print(\"\\nFull EDA & ML Pipeline executed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
